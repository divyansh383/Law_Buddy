{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hare krishna\n"
     ]
    }
   ],
   "source": [
    "print(\"hare krishna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "groq_api_key=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"lala\",\n",
    "    openai_api_version=\"2024-03-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Data base and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector_database(directory_path):\n",
    "    try:\n",
    "        # Load documents\n",
    "        loader = PyPDFDirectoryLoader(directory_path)\n",
    "        docs = loader.load()\n",
    "        if not docs:\n",
    "            raise ValueError(\"No documents found in the directory.\")\n",
    "\n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "        documents = text_splitter.split_documents(docs)\n",
    "        if not documents:\n",
    "            raise ValueError(\"Document splitting resulted in an empty list.\")\n",
    "\n",
    "        # Generate embeddings\n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings_list = embeddings.embed_documents(texts)\n",
    "        if not embeddings_list:\n",
    "            raise ValueError(\"Embeddings generation resulted in an empty list.\")\n",
    "\n",
    "        # Create FAISS database\n",
    "        db = FAISS.from_documents(documents, embeddings)\n",
    "        database = FAISS.load_local('first__vector', embeddings, allow_dangerous_deserialization=True)\n",
    "        database.merge_from(db)\n",
    "        database.save_local('first__vector')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### llm,prompt,chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "             model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### database load and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(input):\n",
    "    llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "             model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Answer the following question based only on the provided context. \n",
    "    Think step by step before providing a detailed answer. \n",
    "    I will tip you $1000 if the user finds the answer helpful. \n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Question: {input}\"\"\")\n",
    "\n",
    "    document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "    database = FAISS.load_local('first__vector',embeddings, allow_dangerous_deserialization= True)\n",
    "    retriever=database.as_retriever()\n",
    "    retrieval_chain=create_retrieval_chain(retriever,document_chain)\n",
    "    response=retrieval_chain.invoke({\"input\":input})\n",
    "\n",
    "    return response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, the answer to the question is:\\n\\nIn 2022, the ACS national poverty rate was 12.6 percent.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"In 2022, the ACS national poverty rate was ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_vector_database(\"attention_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_vector_database(\"us_census\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help! However, I don't see any context provided. Please provide the context, and I'll do my best to answer the question step by step.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"The percentage of the U.S. population with income below 50 percent of their poverty threshold was ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, here is the answer to your question:\\n\\nAccording to the text, between 2021 and 2022, 11 out of the 25 most populous metropolitan areas in the United States saw declines in the uninsured rate, and none experienced an increase in uninsured rates. Specifically, Charlotte-Concord-Gastonia, NC-SC, experienced one of the largest decreases (1.8 percentage points) in the uninsured rate from 2021 to 2022.\\n\\nAdditionally, the text mentions that California expanded Medi-Cal to all adults 50 years or older in May 2022, which may contribute to the higher insured rates in this metropolitan area.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Tell me about Changes in the Uninsured Rate by 25 Most Populous Metropolitan Areas from 2021 to 2022 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, here is the answer to the question:\\n\\nNear poverty refers to individuals with an income-to-poverty ratio between 100 percent to below 125 percent of their poverty threshold. This means that people who are classified as being in near poverty have an income that is above their poverty threshold, but still relatively close to it.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Tell me about near poverty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, I will answer the question step by step.\\n\\nThe context mentions a few cases related to cyber laws, specifically sections of the Information Technology (IT) Act and the Cable TV Networks Regulation Act, 1995. \\n\\nSection 67 of the Information Technology (IT) Act is mentioned as a section under which charges were sought to be quashed in the Rajendra Agrawal v. State of Chhattisgarh case.\\n\\nSection 500 of the IPC is also mentioned as a section under which charges were sought to be quashed in the same case.\\n\\nSection 482 of the Cr PC is mentioned as the section under which the quashing of charges was sought in the Rajendra Agrawal v. State of Chhattisgarh case.\\n\\nThere is no specific information about other sections of the cyber laws in the context provided. \\n\\nHowever, the context does mention some other cases related to cyber laws, such as Praveen Arimbrathodiyil v. Union of India and Union of India v. Sudesh Kumar Singh, which may involve other sections of the cyber laws. \\n\\nTo know more about sections of cyber laws, I would recommend consulting a reliable source such as the official websites of the government or law texts.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Tell me about sections of cyber laws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, I can answer the question about Section 65B of the Evidence Act.\\n\\nSection 65B of the Evidence Act deals with the admissibility and contents of electronic evidence. Specifically, it states that a section 65B(4) certificate is mandatory for secondary evidence and can be given by a person in a responsible position related to device operation or management.\\n\\nFurthermore, the context mentions that Section 65B(4) is a condition precedent to the admissibility of evidence by way of electronic record, and that the court relied on previous rulings to hold that the prosecution should be relieved of the obligation to provide a section 65B(4) certificate if they have made efforts to obtain it but have no control over the relevant third-party companies.\\n\\nOverall, Section 65B of the Evidence Act is crucial in determining the admissibility of electronic evidence in court, and it requires a certificate from a person in a responsible position related to device operation or management to verify the authenticity of the electronic record.\\n\\nPlease let me know if I can assist you further!'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Tell me about section 65B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the answer to the question is:\\n\\nIn the encoder and decoder, both use stacked self-attention and point-wise, fully connected layers.\\n\\n* The encoder is composed of a stack of N=6 identical layers, each with two sub-layers:\\n\\t+ The first sub-layer is a multi-head self-attention mechanism.\\n\\t+ The second sub-layer is a simple, position-wise fully connected feed-forward network.\\n* The decoder also follows a similar architecture, with a stack of identical layers, each with two sub-layers:\\n\\t+ The first sub-layer is a multi-head self-attention mechanism, using the queries from the previous decoder layer.\\n\\t+ The second sub-layer is a simple, position-wise fully connected feed-forward network.\\n\\nI hope this answer helps you!'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"what in encoder and decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_vector_database('attention_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the answer is:\\n\\n**Encoder-Decoder structure**\\n\\nThe text states: \"Most competitive neural sequence transduction models have an encoder-decoder structure [5,2,35].\" This suggests that the Transformer model follows a similar architecture, which consists of an encoder that maps an input sequence to a sequence of continuous representations, and a decoder that generates an output sequence one element at a time.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer(\"Transformer follows this overall architecture using which stacked ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015Issued September 2023Douglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect peopleâ€™s access to health coverage. For example, between 2021 and 2022, the labor market continued to improve, which may have affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under the Continuous Enrollment Provision.\\n2 The American \\nRescue Plan (ARP) enhanced Marketplace premium subsidies for those with incomes above 400 percent of the poverty level as well as for unemployed people.\\n3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = FAISS.load_local('first__vector',embeddings, allow_dangerous_deserialization= True)\n",
    "query=\"Attention is all you need\"\n",
    "result=data.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'72e0d57c-76ca-4edc-9ec4-68def665f041': Document(page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15', metadata={'source': 'uploaded_pdfs\\\\attention.pdf', 'page': 14})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count before: 358\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.load_local('first__vector',embeddings, allow_dangerous_deserialization= True)\n",
    "print(\"count before:\", db.index.ntotal)\n",
    "# db.delete([db.index_to_docstore_id[0]])\n",
    "# print(\"count after:\", db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count before: 428\n",
      "count after: 427\n"
     ]
    }
   ],
   "source": [
    "print(\"count before:\", db.index.ntotal)\n",
    "db.delete([db.index_to_docstore_id[427]])\n",
    "print(\"count after:\", db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count after: 358\n"
     ]
    }
   ],
   "source": [
    "print(\"count after:\", db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(db.index.ntotal - 1, -1, -1):\n",
    "    try:\n",
    "        # Get the docstore ID for the current index\n",
    "        doc_id = db.index_to_docstore_id[i]\n",
    "        \n",
    "        # Delete the entry from FAISS index and docstore\n",
    "        db.delete([doc_id])\n",
    "        \n",
    "        # Add the index to the deleted list\n",
    "        # deleted_indices.append(i)\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting index {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count after: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"count after:\", db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local('first__vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
